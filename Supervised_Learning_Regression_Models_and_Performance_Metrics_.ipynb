{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Supervised Learning: Regression Models and Performance Metrics**"
      ],
      "metadata": {
        "id": "ZdcitB1AXuaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "    - Simple Linear Regression (SLR) is a statistical method used to study the relationship between *one independent variable (X)* and *one dependent variable (Y)*. It assumes that the relationship between X and Y can be represented by a straight line.\n",
        "\n",
        "The mathematical form of Simple Linear Regression is:\n",
        "[\n",
        "Y = \\beta_0 + \\beta_1 X + \\varepsilon\n",
        "]\n",
        "where:\n",
        "\n",
        "* (Y) = dependent variable\n",
        "* (X) = independent variable\n",
        "* (\\beta_0) = intercept\n",
        "* (\\beta_1) = slope of the line\n",
        "* (\\varepsilon) = error term\n",
        "\n",
        "***Purpose of Simple Linear Regression:***\n",
        "\n",
        "* To *predict* the value of the dependent variable based on the independent variable\n",
        "* To *measure the strength and direction* of the relationship between two variables\n",
        "* To understand how changes in the independent variable affect the dependent variable\n"
      ],
      "metadata": {
        "id": "IBljWuDCYSXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "    \n",
        "     The key assumptions of Simple Linear Regression are:\n",
        "\n",
        "      1. ***Linearity*** :\n",
        "                 There is a linear relationship between the independent variable (X) and the dependent variable (Y).\n",
        "\n",
        "      2. ***Independence of errors*** :\n",
        "                The residuals (errors) are independent of each other.\n",
        "\n",
        "      3. ***Homoscedasticity*** :\n",
        "                The variance of the errors is constant for all values of X.\n",
        "\n",
        "      4. ***Normality of errors*** :\n",
        "                The error terms are normally distributed.\n",
        "\n",
        "      5. ***No multicollinearity*** :\n",
        "                Since SLR has only one independent variable, multicollinearity is not an issue (this assumption mainly applies to multiple regression).\n"
      ],
      "metadata": {
        "id": "vo9Es_ZyZBMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "     The mathematical equation of a simple linear regression model is:\n",
        "\n",
        "     [\n",
        "     Y = \\beta_0 + \\beta_1 X + \\varepsilon\n",
        "     ]\n",
        "\n",
        "**Where:**\n",
        "\n",
        "* *(Y)* = Dependent variable (the variable to be predicted)\n",
        "* *(X)* = Independent variable (the predictor variable)\n",
        "* *(\\beta_0)* = Intercept (value of Y when X = 0)\n",
        "* *(\\beta_1)* = Slope of the regression line (change in Y for a one-unit change in X)\n",
        "* *(\\varepsilon)* = Error term (difference between actual and predicted values)"
      ],
      "metadata": {
        "id": "sFDIk7fearNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "    \n",
        "     - A real-world example of simple linear regression is *predicting house prices based on house size*.\n",
        "\n",
        "  * **Independent variable (X)**: Size of the house (in square feet)\n",
        "* **Dependent variable (Y)**: Price of the house\n",
        "\n",
        "  Simple linear regression helps estimate how much the house price increases with an increase in house size.\n"
      ],
      "metadata": {
        "id": "ocP0rt5-bMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is the method of least squares in linear regression?\n",
        "    \n",
        "    - The ***method of least squares*** is a technique used to estimate the parameters of a linear regression model. It determines the best-fitting regression line by ***minimizing the sum of the squares of the residuals*** (errors).\n",
        "\n",
        "      Residuals are the differences between the observed values and the predicted values.\n",
        "      \n",
        "      By minimizing these squared differences, the method ensures the most accurate and reliable regression line.\n"
      ],
      "metadata": {
        "id": "sw2LeKQob8Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is Logistic Regression? How does it differ from Linear Regression?\n",
        "     \n",
        "    - **Logistic Regression** is a statistical technique used for *classification problems, where the dependent variable is **binary** (e.g., Yes/No, 0/1, True/False). It estimates the ***probability*** of an event occurring using a *logistic (sigmoid) function*, which outputs values between 0 and 1.\n",
        "    \n",
        "     ***Differences between Logistic Regression and Linear Regression:***\n",
        "\n",
        "| Linear Regression                         | Logistic Regression                            |\n",
        "| ----------------------------------------- | ---------------------------------------------- |\n",
        "| Used for predicting *continuous values* | Used for predicting *categorical outcomes*   |\n",
        "| Output can be any real number             | Output is a probability between 0 and 1        |\n",
        "| Uses a *straight line* equation         | Uses a *sigmoid (S-shaped) curve*            |\n",
        "| Solved using *least squares method*     | Solved using *maximum likelihood estimation* |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "0TlGrzZ9coit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "   \n",
        "   1. ***Mean Absolute Error (MAE):***\n",
        "   Measures the average of the absolute differences between actual and predicted values. Lower MAE indicates better model performance.\n",
        "\n",
        "   2. ***Mean Squared Error (MSE):***\n",
        "   Calculates the average of the squared differences between actual and predicted values. It penalizes larger errors more heavily.\n",
        "\n",
        "   3. ***R-squared (Coefficient of Determination):***\n",
        "   Indicates how well the independent variable explains the variation in the dependent variable. Its value ranges from 0 to 1."
      ],
      "metadata": {
        "id": "-6algux_eUq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the purpose of the R-squared metric in regression analysis?\n",
        "    \n",
        "    - The *R-squared (R²)* metric measures how well a regression model explains the variability of the dependent variable.\n",
        "\n",
        "* It represents the *proportion of variance in the dependent variable that is explained by the independent variable(s)*.\n",
        "* The value of R-squared ranges from *0 to 1*.\n",
        "\n",
        "  * *R² = 0* → the model explains none of the variability\n",
        "  * *R² = 1* → the model explains all the variability\n",
        "\n",
        "***Purpose of R-squared:***\n",
        "\n",
        "* To evaluate the *goodness of fit* of a regression model\n",
        "* To compare different regression models\n",
        "* To understand how well the model explains the data\n"
      ],
      "metadata": {
        "id": "xr_eRl-_e10b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept."
      ],
      "metadata": {
        "id": "IFvHV5OJfMRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h9KVaFpXqhu",
        "outputId": "4e23ac61-0302-4b7f-c522-28fa4e21ec66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 2.0\n",
            "Intercept: 0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Independent variable\n",
        "Y = np.array([2, 4, 6, 8, 10])               # Dependent variable\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Explanation:*\n",
        "\n",
        "* coef_ gives the *slope (β₁)* of the regression line\n",
        "* intercept_ gives the *intercept (β₀)*\n",
        "* The model learns the relationship ( Y = 2X )\n"
      ],
      "metadata": {
        "id": "Uk3aW7oZf8gF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "     - In a simple linear regression model, the coefficients explain how the dependent variable changes with the independent variable. The model is written as:\n",
        "\n",
        "     - [\n",
        "     Y = \\beta_0 + \\beta_1 X + \\varepsilon\n",
        "     ]\n",
        "\n",
        "* ***Intercept ((\\beta_0))***:\n",
        "  It represents the expected value of the dependent variable *Y when the independent variable X is zero*. It shows the baseline level of Y.\n",
        "\n",
        "* ***Slope ((\\beta_1))***:\n",
        "  It indicates the *average change in Y for a one-unit increase in X*.\n",
        "\n",
        "  * If (\\beta_1 > 0), Y increases as X increases (positive relationship).\n",
        "  * If (\\beta_1 < 0), Y decreases as X increases (negative relationship).\n",
        "\n",
        "   *In summary*, the intercept shows the starting point, while the slope shows the strength and direction of the relationship between X and Y.\n",
        "\n",
        "   This interpretation helps in *understanding, predicting, and explaining* the relationship between variables in real-world problems."
      ],
      "metadata": {
        "id": "zqP3INRpgID3"
      }
    }
  ]
}